{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001dcab3-7377-4b78-a41b-2e6f9aaadfac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Autoreload if improted modules getting changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4460902-e534-47fd-8807-172d1115318a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12073/2621915148.py:8: DeprecationWarning: The current Dask DataFrame implementation is deprecated. \n",
      "In a future release, Dask DataFrame will use a new implementation that\n",
      "contains several improvements including a logical query planning.\n",
      "The user-facing DataFrame API will remain unchanged.\n",
      "\n",
      "The new implementation is already available and can be enabled by\n",
      "installing the dask-expr library:\n",
      "\n",
      "    $ pip install dask-expr\n",
      "\n",
      "and turning the query planning option on:\n",
      "\n",
      "    >>> import dask\n",
      "    >>> dask.config.set({'dataframe.query-planning': True})\n",
      "    >>> import dask.dataframe as dd\n",
      "\n",
      "API documentation for the new implementation is available at\n",
      "https://docs.dask.org/en/stable/dask-expr-api.html\n",
      "\n",
      "Any feedback can be reported on the Dask issue tracker\n",
      "https://github.com/dask/dask/issues \n",
      "\n",
      "To disable this warning in the future, set dask config:\n",
      "\n",
      "    # via Python\n",
      "    >>> dask.config.set({'dataframe.query-planning-warning': False})\n",
      "\n",
      "    # via CLI\n",
      "    dask config set dataframe.query-planning-warning False\n",
      "\n",
      "\n",
      "  import dask.dataframe as dd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.232.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import boto3\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.session import TrainingInput\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel\n",
    "\n",
    "from src.utils import convert_to_ancestry_format\n",
    "from src.model_registry import get_model_registry, AncestryModel\n",
    "\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04499b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d7542e",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea860fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET = 'rnd-sandbox-datasets'\n",
    "BASE_IMAGE_URI = '778090103881.dkr.ecr.us-east-1.amazonaws.com/sagemaker-training-containers/ancestry-recomb:latest'\n",
    "ROLE = 'arn:aws:iam::778090103881:role/ancestry_sagemaker_execution'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf96759",
   "metadata": {},
   "source": [
    "## Input Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e379c15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input CSV with location of VCF files.\n",
    "NAME=\"east-indonesians-alt7\"\n",
    "SAMPLES_SET_PATH = f\"s3://rnd-sandbox-datasets/inference/cohorts/east-indonesians/\"\n",
    "OUTPUT_DIR_PATH = f\"s3://rnd-sandbox-datasets/inference/results/{NAME}/\"\n",
    "MODEL_DIR_PATH = f\"s3://rnd-sandbox-datasets/sagemaker/model-registry/lai/combined/{NAME}/\"\n",
    "MODEL_VERSION = \"0.01\"\n",
    "\n",
    "# Specify number of instances to use per model\n",
    "INSTANCE_COUNT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc447fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class S3Path:\n",
    "    def __init__(self, url: str) -> None:\n",
    "        parsed_url = urlparse(url)\n",
    "        self.url = url\n",
    "        self.path = parsed_url.path[1:]\n",
    "        self.bucket = parsed_url.hostname\n",
    "        self.sagemaker_registry_path = \"sagemaker/model-registry/lai/\"\n",
    "\n",
    "    @property\n",
    "    def input_files(self) -> str:\n",
    "        return os.path.join(self.path, \"input-files/\")\n",
    "\n",
    "    @property\n",
    "    def window_results(self) -> str:\n",
    "        return os.path.join(self.base, self.path, \"window-results/\")\n",
    "\n",
    "    @property\n",
    "    def base_results(self) -> str:\n",
    "        return os.path.join(self.base, self.path, \"base-results/\")\n",
    "\n",
    "    @property\n",
    "    def smooth_results(self) -> str:\n",
    "        return os.path.join(self.base, self.path, \"smooth-results/\")\n",
    "\n",
    "    @property\n",
    "    def model_name(self) -> str:\n",
    "        return self.path.lstrip(self.sagemaker_registry_path).strip(\"/\")\n",
    "\n",
    "    @property\n",
    "    def model_base_path(self) -> str:\n",
    "        return f\"{self.base}{self.sagemaker_registry_path}\"\n",
    "\n",
    "    @property\n",
    "    def base(self) -> str:\n",
    "        return f\"s3://{self.bucket}/\"\n",
    "\n",
    "\n",
    "SAMPLES_SET = S3Path(SAMPLES_SET_PATH)\n",
    "OUTPUT_DIR = S3Path(OUTPUT_DIR_PATH)\n",
    "MODEL_DIR = S3Path(MODEL_DIR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53038e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdfc966c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/input-files/input-data-1.csv\n",
      "upload: s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/input-files/input-data-2.csv\n",
      "upload: s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/input-files/input-data-3.csv\n",
      "upload: s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/input-files/input-data-4.csv\n",
      "upload: s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/input-files/input-data-5.csv\n"
     ]
    }
   ],
   "source": [
    "client = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "def write_file(data, idx):\n",
    "    path = os.path.join(OUTPUT_DIR.input_files, f\"input-data-{idx}.csv\")\n",
    "    client.put_object(Body=data, Bucket=OUTPUT_DIR.bucket, Key=path)\n",
    "    print(f\"upload: s3://{OUTPUT_DIR.bucket}/{path}\")\n",
    "\n",
    "\n",
    "result = client.list_objects(\n",
    "    Bucket=SAMPLES_SET.bucket,\n",
    "    Prefix=SAMPLES_SET.path,\n",
    "    Delimiter=\"/\",\n",
    ")\n",
    "\n",
    "folders = result[\"CommonPrefixes\"]\n",
    "lines_per_file = math.ceil(len(folders) / INSTANCE_COUNT)\n",
    "counter = 1\n",
    "lines = \"\"\n",
    "for i, o in enumerate(folders):\n",
    "    lines += \",\".join([o[\"Prefix\"].split(\"/\")[-2], SAMPLES_SET.bucket, o[\"Prefix\"]]) + \"\\n\"\n",
    "    if (i + 1) % lines_per_file == 0:\n",
    "        write_file(lines, counter)\n",
    "        counter += 1\n",
    "        lines = \"\"\n",
    "\n",
    "if lines:\n",
    "    write_file(lines, counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0febb1",
   "metadata": {},
   "source": [
    "## Read the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd9ff8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ANCESTRY_MODEL = AncestryModel(\n",
    "    MODEL_DIR.model_base_path,\n",
    "    MODEL_DIR.model_name,\n",
    "    MODEL_VERSION,\n",
    ")\n",
    "SUBMODELS = ANCESTRY_MODEL._submodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a4957",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocess\n",
    "\n",
    "Convert dataset into windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e8d60e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:register chr1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr1.2\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/window-results/chr1.2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name vcfwindowizer-1732640a-81f3-4853-825f-382b6e043cb6\n",
      "INFO:root:register chr11.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr11.12\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/window-results/chr11.12/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name vcfwindowizer-13337979-a13c-4ae2-b144-5872e77b1e22\n",
      "INFO:root:register chr13.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr13.14\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/window-results/chr13.14/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name vcfwindowizer-043b3502-9f45-4735-b203-84e180289fef\n",
      "INFO:root:register chr15.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr15.16\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/window-results/chr15.16/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name vcfwindowizer-4db9b580-e197-44e2-bf69-8d3b6d8abc48\n",
      "INFO:root:register chr17.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr17.18\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/window-results/chr17.18/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name vcfwindowizer-9087ce4e-5d7c-416e-bf32-97f7c91d0f33\n",
      "INFO:root:register chr19.20.21.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr19.20.21.22\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/window-results/chr19.20.21.22/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name vcfwindowizer-2da63038-b73e-412a-81d0-41632d6ff9a3\n",
      "INFO:root:register chr3.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr3.4\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/window-results/chr3.4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name vcfwindowizer-8f7fe007-eabe-4c56-b073-8540e646c2eb\n",
      "INFO:root:register chr5.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr5.6\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/window-results/chr5.6/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name vcfwindowizer-cee01c04-5a1b-41f4-93ee-91c897254705\n",
      "INFO:root:register chr7.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr7.8\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/window-results/chr7.8/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name vcfwindowizer-6b366fd9-933b-4b3b-8821-91db3f2f130c\n",
      "INFO:root:register chr9.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr9.10\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/window-results/chr9.10/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name vcfwindowizer-022305d4-4ba3-4499-bc9a-2a570cd5fdc0\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "for SUBMODEL_NAME in SUBMODELS:\n",
    "    print(f\"Running submodel {SUBMODEL_NAME}\")\n",
    "\n",
    "    # base output path\n",
    "    WINDOW_OUTPUT_DIR = f\"{OUTPUT_DIR.window_results}{SUBMODEL_NAME}/\"\n",
    "    print(WINDOW_OUTPUT_DIR)\n",
    "\n",
    "    # model\n",
    "    model_registry = get_model_registry(ANCESTRY_MODEL, [SUBMODEL_NAME])\n",
    "    base_job_name = \"vcfwindowizer\"\n",
    "    job_name = f\"{base_job_name}-{uuid.uuid4()}\"\n",
    "    jobs.append(job_name)\n",
    "\n",
    "    processor = ScriptProcessor(\n",
    "        command=[\"python3\"],\n",
    "        image_uri=BASE_IMAGE_URI,\n",
    "        role=ROLE,\n",
    "        instance_count=INSTANCE_COUNT,\n",
    "        instance_type=\"ml.t3.2xlarge\",\n",
    "        base_job_name=base_job_name,\n",
    "    )\n",
    "    processor.run(\n",
    "        code='src/vcf_preprocess.py',\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=f\"{OUTPUT_DIR.base}{OUTPUT_DIR.input_files}\",\n",
    "                destination='/opt/ml/processing/input/data/',\n",
    "                s3_data_distribution_type=\"ShardedByS3Key\",\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=model_registry[\"sub-models\"][SUBMODEL_NAME][\"model\"][\"base_model_uri\"],\n",
    "                destination='/opt/ml/processing/input/model/',\n",
    "                s3_data_distribution_type=\"FullyReplicated\",\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                source='/opt/ml/processing/output/data/',\n",
    "                destination=WINDOW_OUTPUT_DIR,\n",
    "            ),\n",
    "        ],\n",
    "        logs=False,\n",
    "        wait=False,\n",
    "        job_name=job_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5896c13a",
   "metadata": {},
   "source": [
    "### Waiting for results from preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51c51b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 left\n",
      "9 left\n",
      "8 left\n",
      "7 left\n",
      "6 left\n",
      "5 left\n",
      "4 left\n",
      "3 left\n",
      "2 left\n",
      "1 left\n",
      "Next step\n"
     ]
    }
   ],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "errors = []\n",
    "\n",
    "while len(jobs):\n",
    "    print(f\"{len(jobs)} left\")\n",
    "    for job_name in jobs:\n",
    "        response = client.describe_processing_job(\n",
    "            ProcessingJobName=job_name,\n",
    "        )[\"ProcessingJobStatus\"]\n",
    "\n",
    "        if response in [\"InProgress\", \"Stopping\"]:\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "        if response in [\"Failed\", \"Stopped\"]:\n",
    "            errors.append(job_name)\n",
    "\n",
    "        indx = jobs.index(job_name)\n",
    "        jobs.pop(indx)\n",
    "        break\n",
    "\n",
    "for error in errors:\n",
    "    raise Exception(f\"Processing job {error} failed.\")\n",
    "\n",
    "print(\"Next step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417a8bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Base Layer Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ebc88d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:register chr1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr1.2\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/base-results/chr1.2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: ancestry-recomb-2024-11-06-15-41-45-501\n",
      "INFO:sagemaker:Creating transform job with name: base-4470a53d-1dde-495e-a74d-2f064fe6223c\n",
      "INFO:root:register chr11.12\n",
      "INFO:sagemaker:Creating model with name: ancestry-recomb-2024-11-06-15-41-46-611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr11.12\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/base-results/chr11.12/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: base-f03af665-7375-4703-8e61-7cb69143dd49\n",
      "INFO:root:register chr13.14\n",
      "INFO:sagemaker:Creating model with name: ancestry-recomb-2024-11-06-15-41-47-749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr13.14\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/base-results/chr13.14/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: base-bd435925-dc06-4db7-bfc3-281196381734\n",
      "INFO:root:register chr15.16\n",
      "INFO:sagemaker:Creating model with name: ancestry-recomb-2024-11-06-15-41-50-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr15.16\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/base-results/chr15.16/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: base-c376bb57-ddc6-42d5-ae3e-112cac960a7a\n",
      "INFO:root:register chr17.18\n",
      "INFO:sagemaker:Creating model with name: ancestry-recomb-2024-11-06-15-41-51-682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr17.18\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/base-results/chr17.18/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: base-8b3fbf2f-7c12-47c9-b238-a50420a87b75\n",
      "INFO:root:register chr19.20.21.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr19.20.21.22\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/base-results/chr19.20.21.22/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: ancestry-recomb-2024-11-06-15-41-52-837\n",
      "INFO:sagemaker:Creating transform job with name: base-a2ff1d66-3823-4fb2-aab1-dd957543d8b7\n",
      "INFO:root:register chr3.4\n",
      "INFO:sagemaker:Creating model with name: ancestry-recomb-2024-11-06-15-41-53-918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr3.4\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/base-results/chr3.4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: base-12e2b506-feb4-4d62-9030-6ba0a9408bd2\n",
      "INFO:root:register chr5.6\n",
      "INFO:sagemaker:Creating model with name: ancestry-recomb-2024-11-06-15-41-55-056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr5.6\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/base-results/chr5.6/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: base-ba9589a2-d115-4b0f-9857-d4e77c2a20e0\n",
      "INFO:root:register chr7.8\n",
      "INFO:sagemaker:Creating model with name: ancestry-recomb-2024-11-06-15-41-56-067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr7.8\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/base-results/chr7.8/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: base-3b38a530-75a1-4073-92b2-7b54258d8953\n",
      "INFO:root:register chr9.10\n",
      "INFO:sagemaker:Creating model with name: ancestry-recomb-2024-11-06-15-41-56-982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr9.10\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/base-results/chr9.10/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: base-84089012-02cb-4066-a704-e59601918271\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "for SUBMODEL_NAME in SUBMODELS:\n",
    "    print(f\"Running submodel {SUBMODEL_NAME}\")\n",
    "    job_name = f\"base-{uuid.uuid4()}\"\n",
    "    jobs.append(job_name)\n",
    "\n",
    "    # base output path\n",
    "    BASE_OUTPUT_DIR = f\"{OUTPUT_DIR.base_results}{SUBMODEL_NAME}/\"\n",
    "    print(BASE_OUTPUT_DIR)\n",
    "\n",
    "    # create model\n",
    "    model_registry = get_model_registry(ANCESTRY_MODEL, [SUBMODEL_NAME])\n",
    "    model = Model(\n",
    "        image_uri=BASE_IMAGE_URI,\n",
    "        model_data=model_registry[\"sub-models\"][SUBMODEL_NAME][\"model\"][\"base_model_uri\"],\n",
    "        role=ROLE,\n",
    "    )\n",
    "\n",
    "    # create transformer\n",
    "    transformer = model.transformer(\n",
    "        instance_type=\"ml.m5.12xlarge\", # NOTE: for more than 2 chromosomes use ml.m5.2xlarge\n",
    "        instance_count=INSTANCE_COUNT,\n",
    "        output_path=BASE_OUTPUT_DIR,\n",
    "        strategy='MultiRecord',\n",
    "        max_payload=24,  # NOTE: for ml.m5.2xlarge use 4 as the payload\n",
    "        max_concurrent_transforms=1,\n",
    "        env={'MODEL_SERVER_TIMEOUT': '3600'},\n",
    "    )\n",
    "\n",
    "    # transform data\n",
    "    WINDOW_OUTPUT_DIR = f\"{OUTPUT_DIR.window_results}{SUBMODEL_NAME}/\"\n",
    "    transformer.transform(\n",
    "        data=WINDOW_OUTPUT_DIR,\n",
    "        content_type='text/csv',\n",
    "        split_type='Line',\n",
    "        model_client_config={\n",
    "            'InvocationsMaxRetries': 0,\n",
    "            'InvocationsTimeoutInSeconds': 3600,\n",
    "        },\n",
    "        job_name=job_name,\n",
    "        logs=False,\n",
    "        wait=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7c60d49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 left\n",
      "9 left\n",
      "8 left\n",
      "7 left\n",
      "6 left\n",
      "5 left\n",
      "4 left\n",
      "3 left\n",
      "2 left\n",
      "1 left\n",
      "Next step\n"
     ]
    }
   ],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "errors = []\n",
    "while len(jobs):\n",
    "    print(f\"{len(jobs)} left\")\n",
    "    for job_name in jobs:\n",
    "        response = client.describe_transform_job(\n",
    "            TransformJobName=job_name,\n",
    "        )[\"TransformJobStatus\"]\n",
    "\n",
    "        if response in [\"InProgress\", \"Stopping\"]:\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "        if response in [\"Failed\", \"Stopped\"]:\n",
    "            errors.append(job_name)\n",
    "\n",
    "        indx = jobs.index(job_name)\n",
    "        jobs.pop(indx)\n",
    "        break\n",
    "\n",
    "for error in errors:\n",
    "    raise Exception(f\"Batch transform job {error} failed.\")\n",
    "\n",
    "print(\"Next step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61071a2c",
   "metadata": {},
   "source": [
    "# Smoothing Layer Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f76921a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:register chr1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr1.2\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/smooth-results/chr1.2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://rnd-sandbox-datasets/sagemaker/model-registry/lai/combined/east-indonesians-alt7/0.01/sub-models/chr1.2/smooth/model.tar.gz), script artifact (src/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-778090103881/pytorch-inference-2024-11-06-15-48-59-437/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-06-15-49-01-046\n",
      "INFO:sagemaker:Creating transform job with name: smooth-d8df22c5-0725-4b52-be1e-3e26e872be4a\n",
      "INFO:root:register chr11.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr11.12\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/smooth-results/chr11.12/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://rnd-sandbox-datasets/sagemaker/model-registry/lai/combined/east-indonesians-alt7/0.01/sub-models/chr11.12/smooth/model.tar.gz), script artifact (src/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-778090103881/pytorch-inference-2024-11-06-15-49-02-300/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-06-15-49-03-694\n",
      "INFO:sagemaker:Creating transform job with name: smooth-f6a6efbd-ba6a-461c-ab7f-e63ae41df2d4\n",
      "INFO:root:register chr13.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr13.14\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/smooth-results/chr13.14/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://rnd-sandbox-datasets/sagemaker/model-registry/lai/combined/east-indonesians-alt7/0.01/sub-models/chr13.14/smooth/model.tar.gz), script artifact (src/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-778090103881/pytorch-inference-2024-11-06-15-49-04-697/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-06-15-49-06-698\n",
      "INFO:sagemaker:Creating transform job with name: smooth-5c6752fc-c9ce-4a18-8f7a-46f0ae8fe9d5\n",
      "INFO:root:register chr15.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr15.16\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/smooth-results/chr15.16/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://rnd-sandbox-datasets/sagemaker/model-registry/lai/combined/east-indonesians-alt7/0.01/sub-models/chr15.16/smooth/model.tar.gz), script artifact (src/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-778090103881/pytorch-inference-2024-11-06-15-49-07-732/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-06-15-49-09-174\n",
      "INFO:sagemaker:Creating transform job with name: smooth-b62a2940-5a8e-4327-877a-27c5e0444840\n",
      "INFO:root:register chr17.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr17.18\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/smooth-results/chr17.18/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://rnd-sandbox-datasets/sagemaker/model-registry/lai/combined/east-indonesians-alt7/0.01/sub-models/chr17.18/smooth/model.tar.gz), script artifact (src/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-778090103881/pytorch-inference-2024-11-06-15-49-10-423/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-06-15-49-11-664\n",
      "INFO:sagemaker:Creating transform job with name: smooth-ffd51c28-582e-4f11-a9b6-8c1ac4f4da39\n",
      "INFO:root:register chr19.20.21.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr19.20.21.22\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/smooth-results/chr19.20.21.22/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://rnd-sandbox-datasets/sagemaker/model-registry/lai/combined/east-indonesians-alt7/0.01/sub-models/chr19.20.21.22/smooth/model.tar.gz), script artifact (src/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-778090103881/pytorch-inference-2024-11-06-15-49-12-786/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-06-15-49-14-120\n",
      "INFO:sagemaker:Creating transform job with name: smooth-dab27c02-0895-42f5-bd4f-49513ed3aa4e\n",
      "INFO:root:register chr3.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr3.4\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/smooth-results/chr3.4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://rnd-sandbox-datasets/sagemaker/model-registry/lai/combined/east-indonesians-alt7/0.01/sub-models/chr3.4/smooth/model.tar.gz), script artifact (src/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-778090103881/pytorch-inference-2024-11-06-15-49-15-286/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-06-15-49-16-951\n",
      "INFO:sagemaker:Creating transform job with name: smooth-ad049d14-3adf-4734-a01e-3ac630e6069b\n",
      "INFO:root:register chr5.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr5.6\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/smooth-results/chr5.6/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://rnd-sandbox-datasets/sagemaker/model-registry/lai/combined/east-indonesians-alt7/0.01/sub-models/chr5.6/smooth/model.tar.gz), script artifact (src/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-778090103881/pytorch-inference-2024-11-06-15-49-18-046/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-06-15-49-19-821\n",
      "INFO:sagemaker:Creating transform job with name: smooth-eae863e9-0e72-43b7-bc8b-c07ccb0c830b\n",
      "INFO:root:register chr7.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr7.8\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/smooth-results/chr7.8/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://rnd-sandbox-datasets/sagemaker/model-registry/lai/combined/east-indonesians-alt7/0.01/sub-models/chr7.8/smooth/model.tar.gz), script artifact (src/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-778090103881/pytorch-inference-2024-11-06-15-49-20-853/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-06-15-49-22-489\n",
      "INFO:sagemaker:Creating transform job with name: smooth-c5848d8d-c63d-4a82-9e31-850f68a52807\n",
      "INFO:root:register chr9.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running submodel chr9.10\n",
      "s3://rnd-sandbox-datasets/inference/results/east-indonesians-alt7/smooth-results/chr9.10/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://rnd-sandbox-datasets/sagemaker/model-registry/lai/combined/east-indonesians-alt7/0.01/sub-models/chr9.10/smooth/model.tar.gz), script artifact (src/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-778090103881/pytorch-inference-2024-11-06-15-49-23-515/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-06-15-49-25-292\n",
      "INFO:sagemaker:Creating transform job with name: smooth-b48c1fdb-e6f1-4b20-9a82-3eb11930c28b\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "for SUBMODEL_NAME in SUBMODELS:\n",
    "    print(f\"Running submodel {SUBMODEL_NAME}\")\n",
    "\n",
    "    job_name = f\"smooth-{uuid.uuid4()}\"\n",
    "    jobs.append(job_name)\n",
    "\n",
    "    # get directory\n",
    "    SMOOTH_OUTPUT_DIR = f\"{OUTPUT_DIR.smooth_results}{SUBMODEL_NAME}/\"\n",
    "    print(SMOOTH_OUTPUT_DIR)\n",
    "\n",
    "    # create model\n",
    "    model_registry = get_model_registry(ANCESTRY_MODEL, [SUBMODEL_NAME])\n",
    "\n",
    "    model = PyTorchModel(\n",
    "        model_data=model_registry[\"sub-models\"][SUBMODEL_NAME][\"model\"][\"smooth_model_uri\"],\n",
    "        role=ROLE,\n",
    "        framework_version=\"1.10\",\n",
    "        py_version=\"py38\",\n",
    "        source_dir=\"src/\",\n",
    "        entry_point=\"inference_user.py\",\n",
    "    )\n",
    "\n",
    "    # batch transformer\n",
    "    transformer = model.transformer(\n",
    "        output_path=SMOOTH_OUTPUT_DIR,\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        accept=\"text/tsv\",\n",
    "        strategy='MultiRecord',\n",
    "        max_payload=4,\n",
    "    )\n",
    "\n",
    "    # run transformer\n",
    "    BASE_OUTPUT_DIR = f\"{OUTPUT_DIR.base_results}{SUBMODEL_NAME}/\"\n",
    "    transformer.transform(\n",
    "        data=BASE_OUTPUT_DIR,\n",
    "        content_type='text/tsv',\n",
    "        split_type='Line',\n",
    "        job_name=job_name,\n",
    "        model_client_config={'InvocationsMaxRetries': 0},\n",
    "        logs=False,\n",
    "        wait=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7828c09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 left\n"
     ]
    }
   ],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "errors = []\n",
    "\n",
    "while len(jobs):\n",
    "    print(f\"{len(jobs)} left\")\n",
    "    for job_name in jobs:\n",
    "        response = client.describe_transform_job(\n",
    "            TransformJobName=job_name,\n",
    "        )[\"TransformJobStatus\"]\n",
    "\n",
    "        if response in [\"InProgress\", \"Stopping\"]:\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "        if response in [\"Failed\", \"Stopped\"]:\n",
    "            errors.append(job_name)\n",
    "\n",
    "        indx = jobs.index(job_name)\n",
    "        jobs.pop(indx)\n",
    "        break\n",
    "\n",
    "for error in errors:\n",
    "    raise Exception(f\"Smooth transform job {error} failed.\")\n",
    "\n",
    "print(\"Next step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ed42b",
   "metadata": {},
   "source": [
    "# Base & smoothing layers post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c6b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert base layer results to summary format\n",
    "# generate summary of the smoothing layer output\n",
    "for SUBMODEL_NAME in SUBMODELS:\n",
    "    print(f\"Running submodel {SUBMODEL_NAME}\")\n",
    "\n",
    "    # model registry\n",
    "    model_registry = get_model_registry(ANCESTRY_MODEL, [SUBMODEL_NAME])\n",
    "\n",
    "    parameters_file = model_registry[\"sub-models\"][SUBMODEL_NAME][\"artifacts\"][\"parameters\"]\n",
    "\n",
    "    !rm -rf temp/\n",
    "    !mkdir -p temp/\n",
    "    !aws s3 cp {parameters_file} temp/ --quiet\n",
    "    with open(f'temp/parameters.json', 'rt') as fin:\n",
    "        params = json.load(fin)    \n",
    "        \n",
    "    for layer in [\"base\", \"smooth\"]:\n",
    "        # base output path\n",
    "        path = getattr(OUTPUT_DIR, f\"{layer}_results\")\n",
    "        LAYER_OUTPUT_DIR = f\"{path}{SUBMODEL_NAME}/\"\n",
    "\n",
    "        # read data and convert to regular format\n",
    "        !aws s3 cp --recursive $LAYER_OUTPUT_DIR temp/{layer}/intermediate/ --quiet\n",
    "        !echo \"Files count ({LAYER_OUTPUT_DIR}):\" $(ls temp/{layer}/intermediate/ | wc -l)\n",
    "        \n",
    "        # read base results & save\n",
    "        df_base = convert_to_ancestry_format(\n",
    "            dd.read_csv(f'temp/{layer}/intermediate/*', sep='\\t', header=None, dtype={2: \"object\"}).compute(), \n",
    "            model_registry[\"artifacts\"][\"population_map_uri\"],\n",
    "            params,\n",
    "            pred_by_argmin=bool(layer==\"base\"),\n",
    "        )\n",
    "        df_base.to_csv(f'{OUTPUT_DIR.base}{OUTPUT_DIR.path}summary-results/{layer}_samples.{SUBMODEL_NAME}.tsv.gz', sep='\\t', index=False)\n",
    "        del df_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c26341",
   "metadata": {},
   "source": [
    "### Performing basic analysis of the results (saved to ancestry.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0045cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p temp/\n",
    "!aws s3 cp {OUTPUT_DIR.base}{OUTPUT_DIR.path}summary-results/ temp/ --recursive\n",
    "\n",
    "df_base = dd.read_csv('temp/base_samples.*.tsv.gz', sep='\\t', blocksize=None, dtype={\"sample_id\": \"object\"}).compute()\n",
    "df_base[\"layer\"] = \"base\"\n",
    "\n",
    "df_smooth = dd.read_csv('temp/smooth_samples.*.tsv.gz', sep='\\t', blocksize=None, dtype={\"sample_id\": \"object\"}).compute()\n",
    "df_smooth[\"layer\"] = \"smooth\"\n",
    "\n",
    "df = pd.concat([df_smooth, df_base])\n",
    "del df_base, df_smooth\n",
    "\n",
    "with open('chr_map.json', 'rt') as fin:\n",
    "    chr_fractions = json.load(fin)\n",
    "\n",
    "chr_fractions = {int(k): v for k, v in chr_fractions.items()}\n",
    "window_lengths = df.groupby([\"chrom\"])[\"window\"].nunique().to_dict()\n",
    "chr_map = {k: v/window_lengths[k] for k, v in chr_fractions.items() if k in window_lengths}\n",
    "\n",
    "df[\"weight\"] = df.chrom.map(chr_map)\n",
    "\n",
    "\n",
    "def weight_to_str(x):\n",
    "    x = x/x.sum()\n",
    "    x = x.sort_values(ascending=False)\n",
    "    return \", \".join(f\"{idx[2]}: {v*100:0.2f}\" for idx, v in x.items())\n",
    "\n",
    "\n",
    "df_ = (\n",
    "    df\n",
    "    .groupby([\"sample_id\", \"layer\", \"pred\"])\n",
    "    .agg({\"weight\": \"sum\"})\n",
    "    .groupby([\"sample_id\", \"layer\"])\n",
    "    .agg({\"weight\": weight_to_str})\n",
    "    .rename(columns={\"weight\": \"predicted ancestry\"})\n",
    "    .reset_index()\n",
    "    .sort_values([\"sample_id\", 'layer'])\n",
    ")\n",
    "df_.to_csv(f\"{NAME}-ancestry.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "!rm -rf temp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd79510-d3fb-4353-895f-808fd795496f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
